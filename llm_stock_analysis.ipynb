{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cf66238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mResolved \u001b[1m62 packages\u001b[0m \u001b[2min 6ms\u001b[0m\u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m25 packages\u001b[0m \u001b[2min 13.46s\u001b[0m\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mcomm\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mdebugpy\u001b[0m\u001b[2m==1.8.17\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==7.1.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==9.8.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipython-pygments-lexers\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==8.6.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjupyter-core\u001b[0m\u001b[2m==5.9.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnest-asyncio\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.5\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpexpect\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.52\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.1.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mptyprocess\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.1.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtornado\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.14\u001b[0m\n",
      "\u001b[2mUninstalled \u001b[1m25 packages\u001b[0m \u001b[2min 13.46s\u001b[0m\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1masttokens\u001b[0m\u001b[2m==3.0.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mcomm\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mdebugpy\u001b[0m\u001b[2m==1.8.17\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mdecorator\u001b[0m\u001b[2m==5.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mexecuting\u001b[0m\u001b[2m==2.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipykernel\u001b[0m\u001b[2m==7.1.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipython\u001b[0m\u001b[2m==9.8.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mipython-pygments-lexers\u001b[0m\u001b[2m==1.1.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjedi\u001b[0m\u001b[2m==0.19.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjupyter-client\u001b[0m\u001b[2m==8.6.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjupyter-core\u001b[0m\u001b[2m==5.9.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mmatplotlib-inline\u001b[0m\u001b[2m==0.2.1\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnest-asyncio\u001b[0m\u001b[2m==1.6.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mparso\u001b[0m\u001b[2m==0.8.5\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpexpect\u001b[0m\u001b[2m==4.9.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mprompt-toolkit\u001b[0m\u001b[2m==3.0.52\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpsutil\u001b[0m\u001b[2m==7.1.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mptyprocess\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpure-eval\u001b[0m\u001b[2m==0.2.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpygments\u001b[0m\u001b[2m==2.19.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpyzmq\u001b[0m\u001b[2m==27.1.0\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mstack-data\u001b[0m\u001b[2m==0.6.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtornado\u001b[0m\u001b[2m==6.5.2\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtraitlets\u001b[0m\u001b[2m==5.14.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mwcwidth\u001b[0m\u001b[2m==0.2.14\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9326f63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment managed via uv/pyproject; ensure dependencies installed before running\n",
    "\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from textwrap import dedent\n",
    "from typing import Any, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import ta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27ccf697",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENROUTER_API_KEY = os.environ.get(\"OPENROUTER_API_KEY\")\n",
    "OPENROUTER_BASE_URL = os.environ.get(\"OPENROUTER_BASE_URL\", \"https://openrouter.ai/api/v1\")\n",
    "\n",
    "MODEL_NAME = \"deepseek/deepseek-v3.2\"\n",
    "DEFAULT_TICKER = \"NVDA\"\n",
    "DEFAULT_PERIOD = \"5y\"\n",
    "LOOKBACK_DAYS = 60\n",
    "LLM_TEMPERATURE = 0.3\n",
    "MAX_TOKENS = 800\n",
    "\n",
    "LOG_FILE = Path(\"llm_decision_log.txt\").resolve()\n",
    "LOG_FILE.parent.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96b10a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_stock_data(ticker: str, period: str = DEFAULT_PERIOD) -> pd.DataFrame:\n",
    "    \"\"\"Return daily OHLCV data for the requested ticker.\"\"\"\n",
    "\n",
    "    data = yf.download(\n",
    "        tickers=ticker,\n",
    "        period=period,\n",
    "        interval=\"1d\",\n",
    "        auto_adjust=False,\n",
    "        progress=False,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    if data.empty:\n",
    "        raise ValueError(f\"No data retrieved for ticker {ticker} and period {period}.\")\n",
    "\n",
    "\n",
    "\n",
    "    # Normalize columns to 1D Series for OHLCV\n",
    "\n",
    "    if isinstance(data.columns, pd.MultiIndex):\n",
    "        # If multi-index, select the leaf for the ticker\n",
    "\n",
    "        if ticker in data.columns.get_level_values(-1):\n",
    "            data = data.xs(ticker, axis=1, level=-1)\n",
    "\n",
    "        else:\n",
    "            data.columns = data.columns.get_level_values(0)\n",
    "\n",
    "\n",
    "\n",
    "    for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]:\n",
    "\n",
    "        if col in data.columns and isinstance(data[col], pd.DataFrame):\n",
    "            data[col] = data[col].squeeze(\"columns\")\n",
    "\n",
    "\n",
    "\n",
    "    data = data.dropna(how=\"all\")\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def compute_indicators(df: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    \"\"\"Augment OHLCV data with technical indicators and drop NaNs.\"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"Input price DataFrame is empty.\")\n",
    "\n",
    "    data = df.copy()\n",
    "    close = data[\"Close\"]\n",
    "    high = data[\"High\"]\n",
    "    low = data[\"Low\"]\n",
    "    volume = data[\"Volume\"]\n",
    "\n",
    "    data[\"SMA_10\"] = ta.trend.SMAIndicator(close=close, window=10).sma_indicator()\n",
    "    data[\"SMA_20\"] = ta.trend.SMAIndicator(close=close, window=20).sma_indicator()\n",
    "    data[\"SMA_50\"] = ta.trend.SMAIndicator(close=close, window=50).sma_indicator()\n",
    "    data[\"SMA_100\"] = ta.trend.SMAIndicator(close=close, window=100).sma_indicator()\n",
    "    data[\"SMA_200\"] = ta.trend.SMAIndicator(close=close, window=200).sma_indicator()\n",
    "    data[\"EMA_12\"] = ta.trend.EMAIndicator(close=close, window=12).ema_indicator()\n",
    "    data[\"EMA_26\"] = ta.trend.EMAIndicator(close=close, window=26).ema_indicator()\n",
    "    data[\"RSI_14\"] = ta.momentum.RSIIndicator(close=close, window=14).rsi()\n",
    "\n",
    "    macd = ta.trend.MACD(close=close)\n",
    "    data[\"MACD\"] = macd.macd()\n",
    "    data[\"MACD_Signal\"] = macd.macd_signal()\n",
    "    data[\"MACD_Hist\"] = macd.macd_diff()\n",
    "\n",
    "    bb = ta.volatility.BollingerBands(close=close, window=20, window_dev=2)\n",
    "    data[\"BB_Upper\"] = bb.bollinger_hband()\n",
    "    data[\"BB_Middle\"] = bb.bollinger_mavg()\n",
    "    data[\"BB_Lower\"] = bb.bollinger_lband()\n",
    "\n",
    "    stoch = ta.momentum.StochasticOscillator(high=high, low=low, close=close, window=14, smooth_window=3)\n",
    "    data[\"Stoch_K\"] = stoch.stoch()\n",
    "    data[\"Stoch_D\"] = stoch.stoch_signal()\n",
    "\n",
    "    obv = ta.volume.OnBalanceVolumeIndicator(close=close, volume=volume)\n",
    "    data[\"OBV\"] = obv.on_balance_volume()\n",
    "\n",
    "    data[\"Daily_Return\"] = close.pct_change()\n",
    "    data = data.dropna()\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "237c78c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_llm_input(df: pd.DataFrame, lookback_days: int = LOOKBACK_DAYS) -> str:\n",
    "\n",
    "    \"\"\"Create a textual snapshot of recent price action and indicators.\"\"\"\n",
    "\n",
    "    if df.empty:\n",
    "        raise ValueError(\"Cannot build LLM input from empty DataFrame.\")\n",
    "\n",
    "    window = df.tail(lookback_days)\n",
    "\n",
    "    display_cols = [\n",
    "        \"Close\",\n",
    "        \"SMA_10\",\n",
    "        \"SMA_50\",\n",
    "        \"SMA_200\",\n",
    "        \"EMA_12\",\n",
    "        \"EMA_26\",\n",
    "        \"RSI_14\",\n",
    "        \"MACD\",\n",
    "        \"MACD_Signal\",\n",
    "        \"MACD_Hist\",\n",
    "        \"BB_Upper\",\n",
    "        \"BB_Middle\",\n",
    "        \"BB_Lower\",\n",
    "        \"Stoch_K\",\n",
    "        \"Stoch_D\",\n",
    "        \"OBV\",\n",
    "        \"Volume\",\n",
    "        \"Daily_Return\",\n",
    "    ]\n",
    "\n",
    "    available_cols = [col for col in display_cols if col in window.columns]\n",
    "\n",
    "    snapshot = window[available_cols].copy()\n",
    "\n",
    "    snapshot = snapshot.round({col: 4 for col in available_cols})\n",
    "\n",
    "    lines = []\n",
    "\n",
    "    for idx, row in snapshot.iterrows():\n",
    "        line = (\n",
    "            f\"{idx.date().isoformat()} | \"\n",
    "            f\"Close={float(row.get('Close', float('nan'))):.2f}, \"\n",
    "            f\"SMA10={float(row.get('SMA_10', float('nan'))):.2f}, \"\n",
    "            f\"SMA50={float(row.get('SMA_50', float('nan'))):.2f}, \"\n",
    "            f\"SMA200={float(row.get('SMA_200', float('nan'))):.2f}, \"\n",
    "            f\"EMA12={float(row.get('EMA_12', float('nan'))):.2f}, \"\n",
    "            f\"EMA26={float(row.get('EMA_26', float('nan'))):.2f}, \"\n",
    "            f\"RSI14={float(row.get('RSI_14', float('nan'))):.1f}, \"\n",
    "            f\"MACD={float(row.get('MACD', float('nan'))):.3f}, \"\n",
    "            f\"Signal={float(row.get('MACD_Signal', float('nan'))):.3f}, \"\n",
    "            f\"Hist={float(row.get('MACD_Hist', float('nan'))):.3f}, \"\n",
    "            f\"BBU={float(row.get('BB_Upper', float('nan'))):.2f}, \"\n",
    "            f\"BBM={float(row.get('BB_Middle', float('nan'))):.2f}, \"\n",
    "            f\"BBL={float(row.get('BB_Lower', float('nan'))):.2f}, \"\n",
    "            f\"StochK={float(row.get('Stoch_K', float('nan'))):.1f}, \"\n",
    "            f\"StochD={float(row.get('Stoch_D', float('nan'))):.1f}, \"\n",
    "            f\"OBV={float(row.get('OBV', float('nan'))):.0f}, \"\n",
    "            f\"Vol={float(row.get('Volume', float('nan'))):.0f}, \"\n",
    "            f\"Ret={float(row.get('Daily_Return', float('nan'))):.4f}\"\n",
    "        )\n",
    "\n",
    "        lines.append(line)\n",
    "\n",
    "    price_change_pct = (window[\"Close\"].iloc[-1] / window[\"Close\"].iloc[0] - 1) * 100\n",
    "    daily_returns = window[\"Daily_Return\"].dropna()\n",
    "    annual_vol = daily_returns.std() * np.sqrt(252) * 100 if not daily_returns.empty else 0.0\n",
    "    avg_volume = window[\"Volume\"].mean() if \"Volume\" in window.columns else float(\"nan\")\n",
    "\n",
    "    summary = dedent(\n",
    "        f\"\"\"\n",
    "        Recent performance summary:\n",
    "        - Lookback window: {len(window)} trading days\n",
    "        - Net close change: {price_change_pct:.2f}%\n",
    "        - Annualized volatility (est.): {annual_vol:.2f}%\n",
    "        - Average volume: {avg_volume:,.0f}\n",
    "        \"\"\"\n",
    "    ).strip()\n",
    "\n",
    "    return f\"{summary}\\n\\nDaily snapshots (most recent last):\\n\" + \"\\n\".join(lines)\n",
    "\n",
    "def build_llm_prompt(ticker: str, market_snapshot: str, lookback_days: int = LOOKBACK_DAYS) -> str:\n",
    "    \"\"\"Compose the instruction payload for the LLM.\"\"\"\n",
    "\n",
    "    return dedent(\n",
    "\n",
    "        f\"\"\"\n",
    "        You are an expert quantitative analyst supporting an automated daily stock trading system.\n",
    "        Evaluate the provided market context for ticker {ticker}.\n",
    "\n",
    "        Data characteristics:\n",
    "        - Frequency: daily candles (one decision per trading day).\n",
    "        - Horizon: predict the next trading day's closing price behavior only.\n",
    "        - Goal: produce BUY, SELL, HOLD confidence scores that sum to ~1.\n",
    "\n",
    "        Market context extracted from the last {lookback_days} trading days:\n",
    "\n",
    "        {market_snapshot}\n",
    "\n",
    "        Instructions:\n",
    "        - Analyze trends, momentum, volatility, and mean-reversion signals from the data.\n",
    "        - Determine whether the next day's closing price is likely to rise sharply (BUY), fall sharply (SELL), or stay relatively neutral (HOLD).\n",
    "        - Return a strict JSON object with keys: buy_confidence, sell_confidence, hold_confidence, next_day_view, explanation.\n",
    "        - Confidence values must be floats between 0 and 1 and collectively sum to approximately 1.\n",
    "        - Set next_day_view to BUY, SELL, or HOLD depending on the dominant signal.\n",
    "        - Provide a concise explanation capturing your reasoning; this will be logged privately.\n",
    "        - Do not include any additional text outside the JSON object.\n",
    "        \"\"\"\n",
    "    ).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce33d31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=1)\n",
    "\n",
    "def get_llm_client() -> ChatOpenAI:\n",
    "    \"\"\"Instantiate and cache the LangChain ChatOpenAI client for OpenRouter.\"\"\"\n",
    "\n",
    "    if not OPENROUTER_API_KEY:\n",
    "        raise EnvironmentError(\"OPENROUTER_API_KEY environment variable is not set.\")\n",
    "\n",
    "    return ChatOpenAI(\n",
    "        model=MODEL_NAME,\n",
    "        openai_api_key=OPENROUTER_API_KEY,\n",
    "        openai_api_base=OPENROUTER_BASE_URL,\n",
    "        temperature=LLM_TEMPERATURE,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        timeout=90,\n",
    "    )\n",
    "\n",
    "def invoke_llm(prompt: str) -> str:\n",
    "\n",
    "    \"\"\"Send the prompt to the LLM and return the raw text response.\"\"\"\n",
    "\n",
    "    client = get_llm_client()\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=(\n",
    "                \"You are a disciplined trading assistant. \"\n",
    "                \"Follow instructions exactly and respond with strict JSON.\"\n",
    "            )\n",
    "        ),\n",
    "        HumanMessage(content=prompt),\n",
    "    ]\n",
    "\n",
    "    response = client.invoke(messages)\n",
    "    return response.content\n",
    "\n",
    "def _strip_json_fences(text: str) -> str:\n",
    "    cleaned = text.strip()\n",
    "    if cleaned.startswith(\"```\"):\n",
    "        cleaned = re.sub(r\"^```(?:json)?\", \"\", cleaned, flags=re.IGNORECASE).strip()\n",
    "        cleaned = re.sub(r\"```$\", \"\", cleaned).strip()\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "def parse_llm_decision(raw_text: str) -> Dict[str, Any]:\n",
    "    \"\"\"Parse the LLM JSON payload and enforce expected structure.\"\"\"\n",
    "\n",
    "    cleaned = _strip_json_fences(raw_text)\n",
    "\n",
    "    try:\n",
    "        payload = json.loads(cleaned)\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        match = re.search(r\"\\{.*\\}\", cleaned, flags=re.DOTALL)\n",
    "\n",
    "        if not match:\n",
    "            raise ValueError(\"LLM response is not valid JSON.\") from None\n",
    "\n",
    "        payload = json.loads(match.group())\n",
    "\n",
    "    required_keys = {\"buy_confidence\", \"sell_confidence\", \"hold_confidence\", \"next_day_view\", \"explanation\"}\n",
    "\n",
    "    missing = required_keys - payload.keys()\n",
    "\n",
    "    if missing:\n",
    "        raise ValueError(f\"LLM response missing keys: {sorted(missing)}\")\n",
    "\n",
    "    confidences = {}\n",
    "\n",
    "    for key in [\"buy_confidence\", \"sell_confidence\", \"hold_confidence\"]:\n",
    "        try:\n",
    "            value = float(payload[key])\n",
    "        except (TypeError, ValueError):\n",
    "            raise ValueError(f\"Confidence value for {key} is not numeric.\") from None\n",
    "\n",
    "        value = max(0.0, min(1.0, value))\n",
    "        confidences[key] = value\n",
    "\n",
    "    total = sum(confidences.values())\n",
    "\n",
    "    if total <= 0:\n",
    "        raise ValueError(\"Confidence scores sum to zero.\")\n",
    "\n",
    "    confidences = {k: v / total for k, v in confidences.items()}\n",
    "\n",
    "    decision = {\n",
    "        \"buy_confidence\": confidences[\"buy_confidence\"],\n",
    "        \"sell_confidence\": confidences[\"sell_confidence\"],\n",
    "        \"hold_confidence\": confidences[\"hold_confidence\"],\n",
    "        \"next_day_view\": str(payload.get(\"next_day_view\", \"HOLD\")).upper().strip(),\n",
    "        \"explanation\": str(payload.get(\"explanation\", \"\")).strip(),\n",
    "    }\n",
    "\n",
    "    if decision[\"next_day_view\"] not in {\"BUY\", \"SELL\", \"HOLD\"}:\n",
    "        decision[\"next_day_view\"] = \"HOLD\"\n",
    "\n",
    "    return decision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80c77153",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename=str(LOG_FILE),\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s | %(levelname)s | %(message)s\",\n",
    "    force=True,\n",
    "\n",
    ")\n",
    "\n",
    "def log_llm_decision(ticker: str, last_date: pd.Timestamp, payload: Dict[str, Any]) -> None:\n",
    "    \"\"\"Persist the LLM reasoning and scores to the log file.\"\"\"\n",
    "\n",
    "    date_str = pd.Timestamp(last_date).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    record = {\n",
    "        \"ticker\": ticker,\n",
    "        \"last_data_date\": date_str,\n",
    "        \"buy_confidence\": payload[\"buy_confidence\"],\n",
    "        \"sell_confidence\": payload[\"sell_confidence\"],\n",
    "        \"hold_confidence\": payload[\"hold_confidence\"],\n",
    "        \"next_day_view\": payload[\"next_day_view\"],\n",
    "        \"explanation\": payload[\"explanation\"],\n",
    "    }\n",
    "\n",
    "    logging.info(json.dumps(record, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f86cdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_decision_vector(\n",
    "    ticker: str = DEFAULT_TICKER,\n",
    "    period: str = DEFAULT_PERIOD,\n",
    "    lookback_days: int = LOOKBACK_DAYS,\n",
    ") -> tuple[np.ndarray, Dict[str, Any]]:\n",
    "    \"\"\"Generate the LLM-driven BUY/SELL/HOLD confidence vector and payload.\"\"\"\n",
    "\n",
    "    price_data = fetch_stock_data(ticker=ticker, period=period)\n",
    "    enriched_data = compute_indicators(price_data)\n",
    "    market_snapshot = build_llm_input(enriched_data, lookback_days=lookback_days)\n",
    "    prompt = build_llm_prompt(\n",
    "        ticker=ticker,\n",
    "        market_snapshot=market_snapshot,\n",
    "        lookback_days=lookback_days,\n",
    "    )\n",
    "\n",
    "    raw_response = invoke_llm(prompt)\n",
    "    decision_payload = parse_llm_decision(raw_response)\n",
    "    last_date = enriched_data.index[-1]\n",
    "    log_llm_decision(ticker, last_date, decision_payload)\n",
    "\n",
    "    vector = np.array(\n",
    "        [\n",
    "            decision_payload[\"buy_confidence\"],\n",
    "            decision_payload[\"sell_confidence\"],\n",
    "            decision_payload[\"hold_confidence\"],\n",
    "        ],\n",
    "        dtype=float,\n",
    "    )\n",
    "\n",
    "    return vector, decision_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53905c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM decision vector for NVDA: [0.35 0.45 0.2 ]\n",
      "Decision for NVDA: SELL\n",
      "Reasoning: Price has been in a downtrend since late October peak (~207), with recent closes below key SMAs (SMA50=186.99, SMA200=154.52). Momentum is weak: RSI at 48 (neutral but declining from overbought levels), MACD histogram negative (-0.437) and below signal line, StochK at 50 (neutral). Volatility remains elevated (annualized ~37%). Recent bounce from 177 to 182.77 shows some mean-reversion, but price failed to hold above 180 resistance. Volume on Dec 4 was below average (128.6M vs 190.6M avg), suggesting lack of conviction. Given the downtrend structure, weak momentum, and resistance near moving averages, a pullback is more likely than a sustained rally.\n"
     ]
    }
   ],
   "source": [
    "vector, payload = get_llm_decision_vector(DEFAULT_TICKER)\n",
    "\n",
    "print(f\"LLM decision vector for {DEFAULT_TICKER}: {vector}\")\n",
    "print(f\"Decision for {DEFAULT_TICKER}: {payload.get('next_day_view', 'HOLD')}\")\n",
    "print(f\"Reasoning: {payload.get('explanation', '')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc665-swingsage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
